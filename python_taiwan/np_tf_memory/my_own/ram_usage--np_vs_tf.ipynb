{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2963184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5497823e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9864090"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 10\n",
    "max_length = 10\n",
    "n_instances = sum([reduce(lambda x, y: x*y,\n",
    "                          range(n_classes,n_classes-length,-1)) for length in range(2, max_length+1)\n",
    "])\n",
    "n_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7652cd90",
   "metadata": {},
   "source": [
    "The following `X` will be our dataset (including training/validation/test sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32857cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function getsizeof in module sys:\n",
      "\n",
      "getsizeof(...)\n",
      "    getsizeof(object, default) -> int\n",
      "    \n",
      "    Return the size of object in bytes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sys.getsizeof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4dba9b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       9.9Gi       4.1Gi       578Mi       1.5Gi       4.7Gi\r\n",
      "Swap:           31Gi       2.7Gi        29Gi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34ffacde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((n_instances, max_length, n_classes), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "762404f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       9.9Gi       4.1Gi       584Mi       1.6Gi       4.6Gi\r\n",
      "Swap:           31Gi       2.7Gi        29Gi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f4692b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3945636128"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a1c2a",
   "metadata": {},
   "source": [
    "`3.9` billion bytes! That's more than `3GB`. Let's verify this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8af0e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3945636000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_instances * max_length * n_classes * (32//8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "745b31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c24e117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       9.9Gi       4.1Gi       586Mi       1.6Gi       4.6Gi\r\n",
      "Swap:           31Gi       2.7Gi        29Gi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a049a1",
   "metadata": {},
   "source": [
    "About right: The numbers are quite consistent.\n",
    "\n",
    "<s>By contrast, it seems that `tf.zeros` does not allocate the memory immediately, taking only a memory of `184` bytes.</s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f3140b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       9.9Gi       4.1Gi       587Mi       1.6Gi       4.6Gi\r\n",
      "Swap:           31Gi       2.7Gi        29Gi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91b12625",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = tf.zeros((n_instances, max_length, n_classes), dtype=tf.float32)\n",
    "# float32 unable to be allocated on 4GB-RAM X61s whereas int8 can.\n",
    "#X = tf.zeros((n_instances, max_length, n_classes), dtype=tf.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cf3ca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi        13Gi       383Mi       597Mi       1.6Gi       978Mi\r\n",
      "Swap:           31Gi       2.7Gi        29Gi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0635b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75541439",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79a70234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       9.9Gi       4.1Gi       592Mi       1.6Gi       4.6Gi\r\n",
      "Swap:           31Gi       2.7Gi        29Gi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a396dcf",
   "metadata": {},
   "source": [
    "**(?)** Why my 4GB-RAM Thinkpad X61s still unable to allocate for this `X` using `tf`? Isn't that allocation just a mere `184` bytes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24ebec1",
   "metadata": {},
   "source": [
    "Note that the `free` commands above showed that the RAM consumption equals approximately\n",
    "- `  0GB` for the case of `np.zeros(dtype=np.float32)`\n",
    "- `  1GB` for the case of `tf.zeros(dtype=tf.int8)`\n",
    "- `3.7GB`for the case of `tf.zeros(dtype=tf.float32)`\n",
    "\n",
    "So, even though `sys.getsizeof(X)` shows less in `tf` tensor than in `np` ndarray, the OS feels the other way around.<br>\n",
    "**Suspicious...**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
